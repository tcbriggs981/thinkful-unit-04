{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                         (I, shall, be, late, !, ')  Carroll"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slight</th>\n",
       "      <th>thin</th>\n",
       "      <th>peculiarly</th>\n",
       "      <th>splash</th>\n",
       "      <th>chance</th>\n",
       "      <th>funny</th>\n",
       "      <th>relinquish</th>\n",
       "      <th>help</th>\n",
       "      <th>lonely</th>\n",
       "      <th>liberality</th>\n",
       "      <th>...</th>\n",
       "      <th>curate</th>\n",
       "      <th>uncommon</th>\n",
       "      <th>post</th>\n",
       "      <th>pennyworth</th>\n",
       "      <th>consistent</th>\n",
       "      <th>gratitude</th>\n",
       "      <th>gifted</th>\n",
       "      <th>only</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3064 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  slight thin peculiarly splash chance funny relinquish help lonely  \\\n",
       "0      0    0          0      0      0     0          0    0      0   \n",
       "1      0    0          0      0      0     0          0    0      0   \n",
       "2      0    0          0      0      0     0          0    0      0   \n",
       "3      0    0          0      0      0     0          0    0      0   \n",
       "4      0    0          0      0      0     0          0    0      0   \n",
       "\n",
       "  liberality  ... curate uncommon post pennyworth consistent gratitude gifted  \\\n",
       "0          0  ...      0        0    0          0          0         0      0   \n",
       "1          0  ...      0        0    0          0          0         0      0   \n",
       "2          0  ...      0        0    0          0          0         0      0   \n",
       "3          0  ...      0        0    0          0          0         0      0   \n",
       "4          0  ...      0        0    0          0          0         0      0   \n",
       "\n",
       "  only                                      text_sentence text_source  \n",
       "0    0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
       "1    0  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "2    0  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "3    0                                      (Oh, dear, !)     Carroll  \n",
       "4    0                         (I, shall, be, late, !, ')     Carroll  \n",
       "\n",
       "[5 rows x 3064 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['str_sentence'] = [i.text for i in word_counts.text_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['sent_len'] = [len(i) for i in word_counts['str_sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
      "['PROPN', 'VERB', 'VERB', 'PART', 'VERB', 'ADV', 'ADJ', 'ADP', 'VERB', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT', 'CCONJ', 'ADP', 'VERB', 'NOUN', 'PART', 'VERB', 'PUNCT', 'ADV', 'CCONJ', 'ADV', 'PRON', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'ADJ', 'NOUN', 'VERB', 'VERB', 'PUNCT', 'CCONJ', 'PRON', 'VERB', 'DET', 'NOUN', 'CCONJ', 'NOUN', 'ADP', 'PRON', 'PUNCT', 'PUNCT', 'CCONJ', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'PUNCT', 'PUNCT', 'VERB', 'PROPN', 'PUNCT', 'ADP', 'NOUN', 'CCONJ', 'NOUN', 'PUNCT', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "print(word_counts.loc[0,'text_sentence'])\n",
    "print([x.pos_ for x in word_counts.loc[0,'text_sentence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of each type of word is there?\n",
    "word_counts['cnt_verbs'] = [sum([1 for x in j if x.pos_ == 'VERB']) for j in word_counts.text_sentence]\n",
    "word_counts['cnt_adj'] = [sum([1 for x in j if x.pos_ == 'ADJ']) for j in word_counts.text_sentence]\n",
    "word_counts['cnt_prop'] = [sum([1 for x in j if x.pos_ == 'PROPN']) for j in word_counts.text_sentence]\n",
    "word_counts['cnt_punct'] = [sum([1 for x in j if x.pos_ == 'PUNCT']) for j in word_counts.text_sentence]\n",
    "word_counts['cnt_adv'] = [sum([1 for x in j if x.pos_ == 'ADV']) for j in word_counts.text_sentence]\n",
    "word_counts['cnt_nouns'] = [sum([1 for x in j if x.pos_ == 'NOUN']) for j in word_counts.text_sentence]\n",
    "word_counts['crude_sentiment'] = [j.sentiment for j in word_counts.text_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slight</th>\n",
       "      <th>thin</th>\n",
       "      <th>peculiarly</th>\n",
       "      <th>splash</th>\n",
       "      <th>chance</th>\n",
       "      <th>funny</th>\n",
       "      <th>relinquish</th>\n",
       "      <th>help</th>\n",
       "      <th>lonely</th>\n",
       "      <th>liberality</th>\n",
       "      <th>...</th>\n",
       "      <th>text_source</th>\n",
       "      <th>str_sentence</th>\n",
       "      <th>sent_len</th>\n",
       "      <th>cnt_verbs</th>\n",
       "      <th>cnt_adj</th>\n",
       "      <th>cnt_prop</th>\n",
       "      <th>cnt_punct</th>\n",
       "      <th>cnt_adv</th>\n",
       "      <th>cnt_nouns</th>\n",
       "      <th>crude_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>Alice was beginning to get very tired of sitti...</td>\n",
       "      <td>301</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>So she was considering in her own mind (as wel...</td>\n",
       "      <td>289</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>There was nothing so VERY remarkable in that; ...</td>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>Oh dear!</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>I shall be late!'</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3073 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  slight thin peculiarly splash chance funny relinquish help lonely  \\\n",
       "0      0    0          0      0      0     0          0    0      0   \n",
       "1      0    0          0      0      0     0          0    0      0   \n",
       "2      0    0          0      0      0     0          0    0      0   \n",
       "3      0    0          0      0      0     0          0    0      0   \n",
       "4      0    0          0      0      0     0          0    0      0   \n",
       "\n",
       "  liberality  ... text_source  \\\n",
       "0          0  ...     Carroll   \n",
       "1          0  ...     Carroll   \n",
       "2          0  ...     Carroll   \n",
       "3          0  ...     Carroll   \n",
       "4          0  ...     Carroll   \n",
       "\n",
       "                                        str_sentence sent_len cnt_verbs  \\\n",
       "0  Alice was beginning to get very tired of sitti...      301        13   \n",
       "1  So she was considering in her own mind (as wel...      289        11   \n",
       "2  There was nothing so VERY remarkable in that; ...      140         5   \n",
       "3                                           Oh dear!        8         0   \n",
       "4                                  I shall be late!'       17         2   \n",
       "\n",
       "  cnt_adj cnt_prop cnt_punct cnt_adv cnt_nouns crude_sentiment  \n",
       "0       3        2        10       3        12             0.0  \n",
       "1       7        2         7       7         8             0.0  \n",
       "2       1        2         4       6         2             0.0  \n",
       "3       0        0         1       0         0             0.0  \n",
       "4       1        0         2       0         0             0.0  \n",
       "\n",
       "[5 rows x 3073 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I shall be late!'\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECK\n",
    "word_counts.loc[4,'str_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: shall, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts['shall'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: late, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts['late'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9915360501567398\n",
      "\n",
      "Test set score: 0.8745300751879699\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.86      0.97      0.91      1472\n",
      "     Carroll       0.92      0.65      0.76       656\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      2128\n",
      "   macro avg       0.89      0.81      0.84      2128\n",
      "weighted avg       0.88      0.87      0.87      2128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source', 'str_sentence'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report:\\n',classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with the added Features, the random forest model continues to overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9592476489028213\n",
      "\n",
      "Test set score: 0.9210526315789473\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.92      0.98      0.94      1472\n",
      "     Carroll       0.94      0.80      0.86       656\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      2128\n",
      "   macro avg       0.93      0.89      0.90      2128\n",
      "weighted avg       0.92      0.92      0.92      2128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report:\\n',classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding in the new features improved this model by a couple percentage points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.893730407523511\n",
      "\n",
      "Test set score: 0.8782894736842105\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.87      0.97      0.92      1472\n",
      "     Carroll       0.91      0.67      0.77       656\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      2128\n",
      "   macro avg       0.89      0.82      0.84      2128\n",
      "weighted avg       0.88      0.88      0.87      2128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report:\\n',classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly improved by a couple percentage points, it's inability to recall the Carroll work is somewhat disappointing but this model has the least overfitting, although the logistic regression still outperforms it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 01\n",
    "Find out whether your new model is good at identifying Alice in Wonderland vs any other work, Persuasion vs any other work, or Austen vs any other work. This will involve pulling a new book from the Project Gutenberg corpus (print(gutenberg.fileids()) for a list) and processing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Come, said my soul, Such verses for my Body let us write, (for we are one,) That should I after return, Or, long, long hence, in other spheres, There to some group of mates the chants resuming, (Tallying Earth's soil, trees, winds, tumultuous waves,) Ever with pleas'd smile I may keep on, Ever and ever yet the verses owning as, first, I here and now Signing for Soul and Body, set to them my name, Walt Whitman } One's-Self I Sing One's-self I sing, a simple separate person, Yet utter the word Democratic, the word En-Masse. Of physiology from top to toe I sing, Not physiognomy alone nor brain alone is worthy for the Muse, I say the Form complete is worthier far, The Female equally with the Male I sing. Of Life immense in passion, pulse, and power, Cheerful, for freest action form'd under the\n"
     ]
    }
   ],
   "source": [
    "#Can this differentiate Paradise from Alice in Wonderland?\n",
    "\n",
    "wh = gutenberg.raw('whitman-leaves.txt')\n",
    "wh = re.sub(r'VOLUME \\w+', '', wh)\n",
    "wh = re.sub(r'CHAPTER \\w+', '', wh)\n",
    "wh = text_cleaner(wh)\n",
    "print(type(wh))\n",
    "print(wh[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "692312"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141708"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_doc = nlp(wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_sents = [[sent, \"Whitman\"] for sent in wh_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Come, ,, said, my, soul, ,, Such, verses, for...</td>\n",
       "      <td>Whitman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(That, should, I, after, return, ,, Or, ,, lon...</td>\n",
       "      <td>Whitman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Ever, with, pleas'd, smile, I, may, keep, on,...</td>\n",
       "      <td>Whitman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(I, here, and, now, Signing, for, Soul, and, B...</td>\n",
       "      <td>Whitman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(One's)</td>\n",
       "      <td>Whitman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_sentence text_source\n",
       "0  (Come, ,, said, my, soul, ,, Such, verses, for...     Whitman\n",
       "1  (That, should, I, after, return, ,, Or, ,, lon...     Whitman\n",
       "2  (Ever, with, pleas'd, smile, I, may, keep, on,...     Whitman\n",
       "3  (I, here, and, now, Signing, for, Soul, and, B...     Whitman\n",
       "4                                            (One's)     Whitman"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdf = pd.DataFrame(wh_sents)\n",
    "wdf = wdf.rename({0:'text_sentence', 1:'text_source'}, axis=1)\n",
    "wdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf['str_sentence'] = [x.text for x in wdf['text_sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_words = bag_of_words(wh_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words2 = set(alicewords + wh_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2 = pd.DataFrame(alice_sents + wh_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n",
      "Processing row 5500\n",
      "Processing row 6000\n",
      "Processing row 6500\n",
      "Processing row 7000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>splash</th>\n",
       "      <th>chance</th>\n",
       "      <th>funny</th>\n",
       "      <th>square</th>\n",
       "      <th>help</th>\n",
       "      <th>lonely</th>\n",
       "      <th>queer</th>\n",
       "      <th>gently</th>\n",
       "      <th>hill</th>\n",
       "      <th>mercia</th>\n",
       "      <th>...</th>\n",
       "      <th>frightened</th>\n",
       "      <th>float</th>\n",
       "      <th>dormouse</th>\n",
       "      <th>sacred</th>\n",
       "      <th>thoroughly</th>\n",
       "      <th>apple</th>\n",
       "      <th>hospital</th>\n",
       "      <th>only</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  splash chance funny square help lonely queer gently hill mercia  ...  \\\n",
       "0      0      0     0      0    0      0     0      0    0      0  ...   \n",
       "1      0      0     0      0    0      0     0      0    0      0  ...   \n",
       "2      0      0     0      0    0      0     0      0    0      0  ...   \n",
       "3      0      0     0      0    0      0     0      0    0      0  ...   \n",
       "4      0      0     0      0    0      0     0      0    0      0  ...   \n",
       "\n",
       "  frightened float dormouse sacred thoroughly apple hospital only  \\\n",
       "0          0     0        0      0          0     0        0    0   \n",
       "1          0     0        0      0          0     0        0    0   \n",
       "2          0     0        0      0          0     0        0    0   \n",
       "3          0     0        0      0          0     0        0    0   \n",
       "4          0     0        0      0          0     0        0    0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
       "1  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "3                                      (Oh, dear, !)     Carroll  \n",
       "4                         (I, shall, be, late, !, ')     Carroll  \n",
       "\n",
       "[5 rows x 1590 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts2 = bow_features(sentences2, common_words2)\n",
    "word_counts2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whitman    5709\n",
       "Carroll    1669\n",
       "Name: text_source, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts2.text_source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retry the logistic regression again with the new data / features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a string sentence\n",
    "word_counts2['str_sentence'] = [x.text for x in word_counts2['text_sentence']]\n",
    "\n",
    "# Add the other features we have from before\n",
    "word_counts2['sent_len'] = [len(i) for i in word_counts2['str_sentence']]\n",
    "\n",
    "# How many of each type of word is there?\n",
    "word_counts2['cnt_verbs'] = [sum([1 for x in j if x.pos_ == 'VERB']) for j in word_counts2.text_sentence]\n",
    "word_counts2['cnt_adj'] = [sum([1 for x in j if x.pos_ == 'ADJ']) for j in word_counts2.text_sentence]\n",
    "word_counts2['cnt_prop'] = [sum([1 for x in j if x.pos_ == 'PROPN']) for j in word_counts2.text_sentence]\n",
    "word_counts2['cnt_punct'] = [sum([1 for x in j if x.pos_ == 'PUNCT']) for j in word_counts2.text_sentence]\n",
    "word_counts2['cnt_adv'] = [sum([1 for x in j if x.pos_ == 'ADV']) for j in word_counts2.text_sentence]\n",
    "word_counts2['cnt_nouns'] = [sum([1 for x in j if x.pos_ == 'NOUN']) for j in word_counts2.text_sentence]\n",
    "word_counts2['crude_sentiment'] = [j.sentiment for j in word_counts2.text_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = word_counts2['text_source']\n",
    "X = np.array(word_counts2.drop(['text_sentence','text_source', 'str_sentence'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, Y,test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this improves the score a little bit, looking at it though, most of the issues are coming from the perspective of the Carroll features. I wonder if we balance out the classes, it will fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9640759150474469\n",
      "\n",
      "Test set score: 0.9308943089430894\n",
      "\n",
      "Cross Val score:\n",
      "[0.92776524 0.91751412 0.93107345 0.92429379 0.92881356]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Carroll       0.93      0.76      0.83       674\n",
      "     Whitman       0.93      0.98      0.96      2278\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      2952\n",
      "   macro avg       0.93      0.87      0.89      2952\n",
      "weighted avg       0.93      0.93      0.93      2952\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred2 = lr.predict(X_test2)\n",
    "\n",
    "print('Training set score:', lr.score(X_train2, y_train2))\n",
    "print('\\nTest set score:', lr.score(X_test2, y_test2))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('\\nCross Val score:')\n",
    "print(cross_val_score(lr, X_train2, y_train2, cv = 5))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report:\\n',classification_report(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['splash', 'chance', 'funny', 'square', 'help', 'lonely', 'queer',\n",
       "       'gently', 'hill', 'mercia',\n",
       "       ...\n",
       "       'text_source', 'str_sentence', 'sent_len', 'cnt_verbs', 'cnt_adj',\n",
       "       'cnt_prop', 'cnt_punct', 'cnt_adv', 'cnt_nouns', 'crude_sentiment'],\n",
       "      dtype='object', length=1599)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_s = word_counts2.sample(frac=1, random_state=1)\n",
    "\n",
    "carroll_s = word_s.loc[word_s['text_source']=='Carroll'][:1669]\n",
    "whitman_s = word_s.loc[word_s['text_source']=='Whitman'][:1669]\n",
    "\n",
    "words = pd.concat([carroll_s, whitman_s])\n",
    "words = words.sample(frac=1, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = words['text_source']\n",
    "X = np.array(words.drop(['text_sentence','text_source', 'str_sentence'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, Y,test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9655344655344655\n",
      "\n",
      "Test set score: 0.9041916167664671\n",
      "\n",
      "Cross Val score:\n",
      "[0.9201995  0.89775561 0.8553616  0.915      0.89223058]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Carroll       0.91      0.89      0.90       661\n",
      "     Whitman       0.90      0.92      0.91       675\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1336\n",
      "   macro avg       0.90      0.90      0.90      1336\n",
      "weighted avg       0.90      0.90      0.90      1336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train3, y_train3)\n",
    "\n",
    "y_pred3 = lr.predict(X_test3)\n",
    "\n",
    "print('Training set score:', lr.score(X_train3, y_train3))\n",
    "print('\\nTest set score:', lr.score(X_test3, y_test3))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('\\nCross Val score:')\n",
    "print(cross_val_score(lr, X_train3, y_train3, cv = 5))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report:\\n',classification_report(y_test3, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that didn't improve the overall score of the data but did make prediciting Carroll much more effective in comparison to predicting Whitman. Also looks as if the model with the full dataset is less prone to overfitting than with the balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for data:\n",
      "{'C': 3, 'max_iter': 50, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   41.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Grid Search CV for decision tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#GridSearchCV for random forest \n",
    "param_grid = {'C':[1e9,.5,1,3,5,10], 'max_iter':[50,100,150,300,500], 'penalty':['l1','l2']}\n",
    "\n",
    "# Start the grid search again\n",
    "grid_DT = GridSearchCV(lr, param_grid, cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_DT.fit(X_train3, y_train3)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "# View the accuracy score\n",
    "print('Best score for data:')\n",
    "print(grid_DT.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for data:\n",
      "{'C': 3, 'max_iter': 25, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    3.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Grid Search CV for decision tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#GridSearchCV for random forest \n",
    "param_grid = {'C':[3], 'max_iter':[10,15,25,30,45,50], 'penalty':['l2']}\n",
    "\n",
    "# Start the grid search again\n",
    "grid_DT = GridSearchCV(lr, param_grid, cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_DT.fit(X_train3, y_train3)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "# View the accuracy score\n",
    "print('Best score for data:')\n",
    "print(grid_DT.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.985014985014985\n",
      "\n",
      "Test set score: 0.9094311377245509\n",
      "\n",
      "Cross Val score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91521197 0.90024938 0.85785536 0.9175     0.89473684]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Carroll       0.92      0.90      0.91       661\n",
      "     Whitman       0.90      0.92      0.91       675\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1336\n",
      "   macro avg       0.91      0.91      0.91      1336\n",
      "weighted avg       0.91      0.91      0.91      1336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=3, max_iter=25, penalty='l2')\n",
    "train = lr.fit(X_train3, y_train3)\n",
    "\n",
    "y_pred3 = lr.predict(X_test3)\n",
    "\n",
    "print('Training set score:', lr.score(X_train3, y_train3))\n",
    "print('\\nTest set score:', lr.score(X_test3, y_test3))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('\\nCross Val score:')\n",
    "print(cross_val_score(lr, X_train3, y_train3, cv = 5))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report:\\n',classification_report(y_test3, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the new paramaters on the full dataset\n",
    "The new parameters don't change all that much on the outcome of the data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9681427925892454\n",
      "\n",
      "Test set score: 0.9380081300813008\n",
      "\n",
      "Cross Val score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93679458 0.93107345 0.93672316 0.92655367 0.93220339]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Carroll       0.93      0.76      0.83       674\n",
      "     Whitman       0.93      0.98      0.96      2278\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      2952\n",
      "   macro avg       0.93      0.87      0.89      2952\n",
      "weighted avg       0.93      0.93      0.93      2952\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=3, max_iter=25, penalty='l2')\n",
    "train = lr.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred3 = lr.predict(X_test2)\n",
    "\n",
    "print('Training set score:', lr.score(X_train2, y_train2))\n",
    "print('\\nTest set score:', lr.score(X_test2, y_test2))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('\\nCross Val score:')\n",
    "print(cross_val_score(lr, X_train2, y_train2, cv = 5))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report:\\n',classification_report(y_test2, y_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
